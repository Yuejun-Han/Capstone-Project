{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Enformer_Prediction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yuejun-Han/Capstone-Project/blob/main/2_Enformer_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "pN2aNsBWd2Ph"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook demonstrates how to utlize Enformer to make gene expression prediction upon the data (from GEUVADIS/1000 genomes dataset) that we prepared from the previous notebook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si-w2NPretDg",
        "tags": []
      },
      "source": [
        "### Major Steps\n",
        "\n",
        "- Set up the environment\n",
        "- Get/check the input data\n",
        "- Make predictions and store them\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCCJsjaHwTYC"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbfKKYSgouvH"
      },
      "source": [
        "kipoiseq is a package that helps us to extract sequences from fasta files given some intervals. We will install the package. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eg8hcb45wqMM"
      },
      "outputs": [],
      "source": [
        "!pip install kipoiseq==0.5.2 --quiet > /dev/null\n",
        "# You can ignore the pyYAML error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq7uxLyqiXfj"
      },
      "source": [
        "Biopython is a python package that helps us do many bioinfomatic analysis in python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO3AtZ-Y50Nw",
        "outputId": "55281203-5163-4813-9338-888eaac66ecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Biopython\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from Biopython) (1.21.6)\n",
            "Installing collected packages: Biopython\n",
            "Successfully installed Biopython-1.79\n"
          ]
        }
      ],
      "source": [
        "!pip install Biopython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCDk7UQPG0Lr"
      },
      "source": [
        "### Setting up our environments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTi5WYntpAoA"
      },
      "source": [
        "Import packages that we need later. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRI9KisU11bM"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub # for interacting with saved models and tensorflow hub\n",
        "import joblib\n",
        "import gzip # for manipulating compressed files\n",
        "import kipoiseq # for manipulating fasta files\n",
        "from kipoiseq import Interval # same as above, really\n",
        "import pyfaidx # to index our reference genome file\n",
        "import pandas as pd # for manipulating dataframes\n",
        "import numpy as np # for numerical computations\n",
        "import pickle # for saving large objects\n",
        "import os, sys # functions for interacting with the operating system\n",
        "import random  \n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "connect to Google Drive to store results and data pernemently in cloud.   "
      ],
      "metadata": {
        "id": "Okr-qQcb4ZvZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTzF3SHvWYFY",
        "outputId": "fecf4eee-3c4a-4ecd-e824-9f7335a01c1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqR7ol3rxrtM"
      },
      "source": [
        "Because Enformer is a deep learning method that consumes high computational power, we are going to change the set up of Google Colab here to utlize GPU to help us speed up the prediction process. \n",
        "\n",
        "Google Colab gives us some GPU access. This limited GPU is available to anyone with a Google account, who has signed up to use Colaboratory. We will begin by changing the runtime type to GPU. Follow the instruction below by clicking on \"Runtime -> Change runtime type -> GPU\" in the menu bar below the title of this notebook. \n",
        "\n",
        "**Start the colab kernel with GPU**: Runtime -> Change runtime type -> GPU\n",
        "\n",
        "\n",
        "Below, we import tensorflow as tf, and check that the runtime has been changed to GPU. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTGOLrbZxNHK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# Make sure the GPU is enabled \n",
        "assert tf.config.list_physical_devices('GPU'), 'Start the colab kernel with GPU: Runtime -> Change runtime type -> GPU'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOCpY-KSWfT2"
      },
      "source": [
        "Create a folder called \"Capstone_Project_2022\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIOrkP_aXM7f"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"/content/drive/MyDrive/Capstone_Project_2022/results/\"):\n",
        "  !mkdir -p \"/content/drive/MyDrive/Capstone_Project_2022/results/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lThC04sKMty_"
      },
      "outputs": [],
      "source": [
        "local_path = '/content/drive/MyDrive/Capstone_Project_2022/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0F1A9AaCrkQ"
      },
      "outputs": [],
      "source": [
        "transform_path = 'gs://dm-enformer/models/enformer.finetuned.SAD.robustscaler-PCA500-robustscaler.transform.pkl'\n",
        "model_path = 'https://tfhub.dev/deepmind/enformer/1'\n",
        "fasta_file = local_path+'genome.fa'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omj-KERcwSdB"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKGGQIMjtdif"
      },
      "source": [
        "Next, we have some functions that will help us along the way. Classes and methods defined in this code block can be found in the [original Enformer usage colab notebook](https://colab.research.google.com/github/deepmind/deepmind_research/blob/master/enformer/enformer-usage.ipynb). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47E4AEgLx1VT"
      },
      "outputs": [],
      "source": [
        "# @title `Enformer`, `EnformerScoreVariantsNormalized`, `EnformerScoreVariantsPCANormalized`,\n",
        "SEQUENCE_LENGTH = 393216\n",
        "\n",
        "class Enformer:\n",
        "\n",
        "  def __init__(self, tfhub_url):\n",
        "    self._model = hub.load(tfhub_url).model\n",
        "\n",
        "  def predict_on_batch(self, inputs):\n",
        "    predictions = self._model.predict_on_batch(inputs)\n",
        "    return {k: v.numpy() for k, v in predictions.items()}\n",
        "\n",
        "#  @tf.function\n",
        "  def contribution_input_grad(self, input_sequence,\n",
        "                              target_mask, output_head='human'):\n",
        "    input_sequence = input_sequence[tf.newaxis]\n",
        "\n",
        "    target_mask_mass = tf.reduce_sum(target_mask)\n",
        "    with tf.GradientTape() as tape:\n",
        "      tape.watch(input_sequence)\n",
        "      prediction = tf.reduce_sum(\n",
        "          target_mask[tf.newaxis] *\n",
        "          self._model.predict_on_batch(input_sequence)[output_head]) / target_mask_mass\n",
        "\n",
        "    input_grad = tape.gradient(prediction, input_sequence) * input_sequence\n",
        "    input_grad = tf.squeeze(input_grad, axis=0)\n",
        "    return tf.reduce_sum(input_grad, axis=-1)\n",
        "\n",
        "\n",
        "class EnformerScoreVariantsRaw:\n",
        "\n",
        "  def __init__(self, tfhub_url, organism='human'):\n",
        "    self._model = Enformer(tfhub_url)\n",
        "    self._organism = organism\n",
        "  \n",
        "  def predict_on_batch(self, inputs):\n",
        "    ref_prediction = self._model.predict_on_batch(inputs['ref'])[self._organism]\n",
        "    alt_prediction = self._model.predict_on_batch(inputs['alt'])[self._organism]\n",
        "\n",
        "    return alt_prediction.mean(axis=1) - ref_prediction.mean(axis=1)\n",
        "\n",
        "\n",
        "class EnformerScoreVariantsNormalized:\n",
        "\n",
        "  def __init__(self, tfhub_url, transform_pkl_path,\n",
        "               organism='human'):\n",
        "    assert organism == 'human', 'Transforms only compatible with organism=human'\n",
        "    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n",
        "    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n",
        "      transform_pipeline = joblib.load(f)\n",
        "    self._transform = transform_pipeline.steps[0][1]  # StandardScaler.\n",
        "    \n",
        "  def predict_on_batch(self, inputs):\n",
        "    scores = self._model.predict_on_batch(inputs)\n",
        "    return self._transform.transform(scores)\n",
        "\n",
        "\n",
        "class EnformerScoreVariantsPCANormalized:\n",
        "\n",
        "  def __init__(self, tfhub_url, transform_pkl_path,\n",
        "               organism='human', num_top_features=500):\n",
        "    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n",
        "    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n",
        "      self._transform = joblib.load(f)\n",
        "    self._num_top_features = num_top_features\n",
        "    \n",
        "  def predict_on_batch(self, inputs):\n",
        "    scores = self._model.predict_on_batch(inputs)\n",
        "    return self._transform.transform(scores)[:, :self._num_top_features]\n",
        "\n",
        "\n",
        "# @title `variant_centered_sequences`\n",
        "\n",
        "class FastaStringExtractor:\n",
        "    \n",
        "    def __init__(self, fasta_file):\n",
        "        self.fasta = pyfaidx.Fasta(fasta_file)\n",
        "        self._chromosome_sizes = {k: len(v) for k, v in self.fasta.items()}\n",
        "\n",
        "    def extract(self, interval: Interval, **kwargs) -> str:\n",
        "        # Truncate interval if it extends beyond the chromosome lengths.\n",
        "        chromosome_length = self._chromosome_sizes[interval.chrom]\n",
        "        trimmed_interval = Interval(interval.chrom,\n",
        "                                    max(interval.start, 0),\n",
        "                                    min(interval.end, chromosome_length),\n",
        "                                    )\n",
        "        # pyfaidx wants a 1-based interval\n",
        "        sequence = str(self.fasta.get_seq(trimmed_interval.chrom,\n",
        "                                          trimmed_interval.start + 1,\n",
        "                                          trimmed_interval.stop).seq).upper()\n",
        "        # Fill truncated values with N's.\n",
        "        pad_upstream = 'N' * max(-interval.start, 0)\n",
        "        pad_downstream = 'N' * max(interval.end - chromosome_length, 0)\n",
        "        return pad_upstream + sequence + pad_downstream\n",
        "\n",
        "    def close(self):\n",
        "        return self.fasta.close()\n",
        "\n",
        "\n",
        "def one_hot_encode(sequence):\n",
        "  return kipoiseq.transforms.functional.one_hot_dna(sequence).astype(np.float32)\n",
        "\n",
        "# @title `plot_tracks`\n",
        "\n",
        "def plot_tracks(tracks, interval, height=1.5):\n",
        "  fig, axes = plt.subplots(len(tracks), 1, figsize=(20, height * len(tracks)), sharex=True)\n",
        "  for ax, (title, y) in zip(axes, tracks.items()):\n",
        "    ax.fill_between(np.linspace(interval.start, interval.end, num=len(y)), y)\n",
        "    ax.set_title(title)\n",
        "    sns.despine(top=True, right=True, bottom=True)\n",
        "  ax.set_xlabel(str(interval))\n",
        "  plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t0sQ5Tuek2B"
      },
      "source": [
        "Here, we define some utility functions for ourselves, to help us make predictions and analyse our predictions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmvG1Ta46Xf3"
      },
      "outputs": [],
      "source": [
        "import Bio\n",
        "\n",
        "from Bio.Seq import Seq\n",
        "def create_rev_complement(dna_string):\n",
        "    return(str(Seq(dna_string).reverse_complement()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UaDZTBQR-ys"
      },
      "outputs": [],
      "source": [
        "def prepare_for_quantify_prediction_per_TSS(predictions, gene, tss_df):\n",
        "\n",
        "  '''\n",
        "\n",
        "  Parameters:\n",
        "          predicitions (A numpy array): All predictions from the track\n",
        "          gene (a gene name, character): a gene\n",
        "          tss_df: a list of dataframe of genes and their transcription start sites\n",
        "  Returns:\n",
        "          A dictionary of cage experiment predictions and a list of transcription start sites\n",
        "\n",
        "  '''\n",
        "  \n",
        "  output = dict()\n",
        "  for tdf in tss_df:\n",
        "    if gene not in tdf.genes.values:\n",
        "      continue\n",
        "    gene_tss_list = tdf[tdf.genes == gene].txStart_Sites.apply(str).values\n",
        "    gene_tss_list = [t.split(', ') for t in gene_tss_list]\n",
        "    gene_tss_list = [int(item) for nestedlist in gene_tss_list for item in nestedlist]\n",
        "    gene_tss_list = list(set(gene_tss_list))\n",
        "  output['cage_predictions'] = predictions[:, 5110] # a numpy array\n",
        "  output['gene_TSS'] = gene_tss_list # a list\n",
        "\n",
        "\n",
        "  return(output) # a dictionary\n",
        "\n",
        "def quantify_prediction_per_TSS(low_range, TSS, cage_predictions):\n",
        "\n",
        "  '''\n",
        "  Parameters:\n",
        "          low_range (int): The lower interval\n",
        "          TSS (list of integers): A list of TSS for a gene\n",
        "          cage_predictions: A 1D numpy array or a vector of predictions from enformer corresponding to track 5110 or CAGE predictions\n",
        "  Returns:\n",
        "          A dictionary of gene expression predictions for each TSS for a gene\n",
        "    '''\n",
        "  tss_predictions = dict()\n",
        "  for tss in TSS:\n",
        "    bin_start = low_range + ((768 + 320) * 128)\n",
        "    count = -1\n",
        "    while bin_start < tss:\n",
        "      bin_start = bin_start + 128\n",
        "      count += 1 \n",
        "    if count >= len(cage_predictions)-1:\n",
        "      continue\n",
        "    cage_preds = cage_predictions[count - 1] + cage_predictions[count] + cage_predictions[count + 1]\n",
        "    tss_predictions[tss] = cage_preds\n",
        "\n",
        "  return(tss_predictions)\n",
        "\n",
        "def collect_intervals(chromosomes, gene_list=None):\n",
        "\n",
        "  '''\n",
        "    Parameters : \n",
        "      chromosomes : a list of chromosome numbers; each element should be a string format\n",
        "      gene_list : a list of genes; the genes should be located on those chromosomes\n",
        "\n",
        "    Returns :\n",
        "      A dictionary of genes (from gene_list) and their intervals within their respective chromosomes\n",
        "  '''\n",
        "\n",
        "  gene_intervals = {} # Collect intervals for our genes of interest\n",
        "\n",
        "  for chrom in chromosomes:\n",
        "    with open(\"/content/drive/MyDrive/Capstone_Project_2022/data/gene_chroms/gene_\"+ chrom + \".txt\", \"r\") as chrom_genes:\n",
        "      for line in chrom_genes:\n",
        "        split_line = line.strip().split(\"\\t\")\n",
        "        gene_intervals[split_line[2]] = [\n",
        "                                          split_line[0],\n",
        "                                          int(split_line[3]),\n",
        "                                          int(split_line[4])\n",
        "                                        ]\n",
        "\n",
        "  if isinstance(gene_list, list): # if the user has supplied a list of genes they are interested in\n",
        "    use_genes = dict((k, gene_intervals[k]) for k in gene_list if k in gene_intervals)\n",
        "    return(use_genes)\n",
        "  elif isinstance(gene_list, type(None)):\n",
        "    return(gene_intervals)\n",
        "\n",
        "\n",
        "def run_predictions(gene_intervals, tss_dataframe, individuals_list=None):\n",
        "  '''\n",
        "  Parameters :\n",
        "    gene_intervals : the results from calling `collect_intervals`\n",
        "    tss_dataframe : a list of the TSSs dataframes i.e. the TSS for the genes in the chromosomes\n",
        "    individuals_list : a list of individuals on which we want to make predictions; defaults to None\n",
        "\n",
        "  Returns :\n",
        "    A list of predictions; the first element is the predictions around the TSS for each gene. The second is the prediction across CAGE tracks\n",
        "  '''\n",
        "\n",
        "  gene_output = dict()\n",
        "  gene_predictions = dict()\n",
        "\n",
        "  for gene in gene_intervals.keys():\n",
        "    gene_interval = gene_intervals[gene]\n",
        "    target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n",
        "                                        gene_interval[1],\n",
        "                                        gene_interval[2]) # creates an interval to select the right sequences\n",
        "    target_fa = fasta_extractor.extract(target_interval.resize(SEQUENCE_LENGTH))  # extracts the fasta sequences, and resizes such that it is compatible with the sequence_length\n",
        "    window_coords = target_interval.resize(SEQUENCE_LENGTH) # we also need information about the start and end locations after resizing\n",
        "    try:\n",
        "      cur_gene_vars = pd.read_csv(\"/content/drive/MyDrive/Capstone_Project_2022/data/individual_beds/chr\" + gene_interval[0] + \"/chr\" + gene_interval[0] + \"_\"+ gene + \".bed\", sep=\"\\t\", header=0) # read in the appropriate bed file for the gene\n",
        "    except:\n",
        "      continue\n",
        "    individual_results = dict()\n",
        "    individual_prediction = dict()\n",
        "\n",
        "    if isinstance(individuals_list, list) or isinstance(individuals_list, type(np.empty([1, 1]))):\n",
        "      use_individuals = individuals_list\n",
        "    elif isinstance(individuals_list, type(None)):\n",
        "      use_individuals = cur_gene_vars.columns[4:]\n",
        "\n",
        "    for individual in use_individuals:\n",
        "      print('Currently on gene {}, and predicting on individual {}...'.format(gene, individual))\n",
        "      # two haplotypes per individual\n",
        "      haplo_1 = list(target_fa[:])\n",
        "      haplo_2 = list(target_fa[:])\n",
        "\n",
        "      ref_mismatch_count = 0\n",
        "      for i,row in cur_gene_vars.iterrows():\n",
        "\n",
        "        geno = row[individual].split(\"|\")\n",
        "        if (row[\"POS\"]-window_coords.start-1) >= len(haplo_2):\n",
        "          continue\n",
        "        if (row[\"POS\"]-window_coords.start-1) < 0:\n",
        "          continue\n",
        "        if geno[0] == \"1\":\n",
        "          haplo_1[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n",
        "        if geno[1] == \"1\":\n",
        "          haplo_2[row[\"POS\"]-window_coords.start-1] = row[\"ALT\"]\n",
        "\n",
        "      # predict on the individual's two haplotypes\n",
        "      prediction_1 = model.predict_on_batch(one_hot_encode(\"\".join(haplo_1))[np.newaxis])['human'][0]\n",
        "      prediction_2 = model.predict_on_batch(one_hot_encode(\"\".join(haplo_2))[np.newaxis])['human'][0]\n",
        "\n",
        "      temp_predictions = [prediction_1[:, 5110], prediction_2[:, 5110]] # CAGE predictions we are interested in \n",
        "      individual_prediction[individual] = temp_predictions\n",
        "\n",
        "      # Calculate TSS CAGE expression which correspond to column 5110 of the predictions above\n",
        "      temp_list = list()\n",
        "\n",
        "      pred_prepared_1 = prepare_for_quantify_prediction_per_TSS(predictions=prediction_1, gene=gene, tss_df=tss_dataframe)\n",
        "      tss_predictions_1 = quantify_prediction_per_TSS(low_range = window_coords.start, TSS=pred_prepared_1['gene_TSS'], cage_predictions=pred_prepared_1['cage_predictions'])\n",
        "\n",
        "      pred_prepared_2 = prepare_for_quantify_prediction_per_TSS(predictions=prediction_2, gene=gene, tss_df=tss_dataframe)\n",
        "      tss_predictions_2 = quantify_prediction_per_TSS(low_range = window_coords.start, TSS=pred_prepared_2['gene_TSS'], cage_predictions=pred_prepared_2['cage_predictions'])\n",
        "\n",
        "      temp_list.append(tss_predictions_1)\n",
        "      temp_list.append(tss_predictions_2) # results here are a dictionary for each TSS for each haplotype\n",
        "\n",
        "      individual_results[individual] = temp_list # save for the individual\n",
        "\n",
        "    gene_output[gene] = individual_results\n",
        "    gene_predictions[gene] = individual_prediction\n",
        "\n",
        "  return([gene_output, gene_predictions])\n",
        "\n",
        "\n",
        "def collect_target_intervals(gene_intervals):\n",
        "\n",
        "  '''\n",
        "  Returns a dictionary of Interval objects (from kipoiseq) for each gene corresponding to the locations of the gene\n",
        "  '''\n",
        "\n",
        "  target_intervals_dict = dict()\n",
        "\n",
        "  for gene in gene_intervals.keys():\n",
        "    gene_interval = gene_intervals[gene]\n",
        "    target_interval = kipoiseq.Interval(\"chr\" + gene_interval[0],\n",
        "                                        gene_interval[1],\n",
        "                                        gene_interval[2])\n",
        "    target_intervals_dict[gene] = target_interval\n",
        "\n",
        "  return(target_intervals_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OCS8CUtIQ-V"
      },
      "outputs": [],
      "source": [
        "def plot_predixcan_vs_geuvadis(interested_gene, interested_individuals, geuvadis_expression, predixcan_expression):\n",
        "\n",
        "  '''\n",
        "  Show a plot and return correlation coefficient\n",
        "  '''\n",
        "  # from predixcan expression\n",
        "  df_predixcan = predixcan_expression[predixcan_expression.gene_name == interested_gene].loc[:,interested_individuals]\n",
        "  # from enformer\n",
        "  df_geuvadis = geuvadis_expression[geuvadis_expression.gene_name == interested_gene].loc[:,interested_individuals]\n",
        "\n",
        "  # concatenate both\n",
        "  df_all = pd.concat([df_predixcan, df_geuvadis], axis=0)\n",
        "  df_all.index = ['Predixcan', 'GEUVADIS']\n",
        "\n",
        "  # plotting\n",
        "  sns.regplot(x=df_all.iloc[0,:], y=df_all.iloc[1,:], color='red').set(title='Predixcan vs. GEUVADIS predictions on {} individuals for gene {}'.format(len(df_all.columns), interested_gene))\n",
        "\n",
        "  # correlation coefficient\n",
        "  corr_coef = np.corrcoef(x=df_all.iloc[0,:], y=df_all.iloc[1,:])[0][1]\n",
        "\n",
        "  return([df_all, corr_coef])\n",
        "\n",
        "def plot_enformer_vs_predixcan(prediction_results, interested_gene, interested_individuals, predixcan_expression, how='sum'):\n",
        "\n",
        "  '''\n",
        "  Show a plot and return correlation coefficient\n",
        "  '''\n",
        "\n",
        "  enformer_predictions = dict()\n",
        "\n",
        "  for gene, individuals in prediction_results[0].items():\n",
        "    temp_individual = dict()\n",
        "    for individual, haplo_predictions in individuals.items():\n",
        "      temp = list()\n",
        "      for i in range(0, len(haplo_predictions[0])):\n",
        "        temp.append(list(haplo_predictions[0].values())[i] + list(haplo_predictions[1].values())[i])\n",
        "      if how == 'sum':\n",
        "        temp_individual[individual] = np.sum(temp)\n",
        "      elif how == 'max':\n",
        "        temp_individual[individual] = np.max(temp)\n",
        "    enformer_predictions[gene] = temp_individual\n",
        "\n",
        "  # from predixcan expression\n",
        "  df_predixcan = predixcan_expression[predixcan_expression.gene_name == interested_gene].loc[:,interested_individuals]\n",
        "  # from enformer\n",
        "  df_enformer = pd.DataFrame(enformer_predictions[interested_gene], index=[0]).loc[:, df_predixcan.columns]\n",
        "\n",
        "  # concatenate both\n",
        "  df_all = pd.concat([df_enformer, df_predixcan], axis=0)\n",
        "  df_all.index = ['Enformer', 'Predixcan']\n",
        "\n",
        "  # plotting\n",
        "  sns.regplot(x=df_all.iloc[0,:], y=df_all.iloc[1,:], color='red').set(title='Predixcan vs. Enformer predictions on {} individuals for gene {}'.format(len(df_all.columns), interested_gene))\n",
        "\n",
        "  # correlation coefficient\n",
        "  corr_coef_predix = np.corrcoef(x=df_all.iloc[0,:], y=df_all.iloc[1,:])[0][1]\n",
        "\n",
        "  return([df_all, corr_coef_predix])\n",
        "\n",
        "\n",
        "def plot_enformer_vs_geuvadis(prediction_results, interested_gene, interested_individuals, geuvadis_expression, how='sum'):\n",
        "\n",
        "  '''\n",
        "  Show a plot and return correlation coefficient\n",
        "  '''\n",
        "\n",
        "  enformer_predictions = dict()\n",
        "\n",
        "  for gene, individuals in prediction_results[0].items():\n",
        "    temp_individual = dict()\n",
        "    for individual, haplo_predictions in individuals.items():\n",
        "      temp = list()\n",
        "      for i in range(0, len(haplo_predictions[0])):\n",
        "        temp.append(list(haplo_predictions[0].values())[i] + list(haplo_predictions[1].values())[i])\n",
        "      if how == 'sum':\n",
        "        temp_individual[individual] = np.sum(temp)\n",
        "      elif how == 'max':\n",
        "        temp_individual[individual] = np.max(temp)\n",
        "    enformer_predictions[gene] = temp_individual\n",
        "\n",
        "  # from geuvadis expression\n",
        "  df_geuvadis = geuvadis_expression[geuvadis_expression.gene_name == interested_gene].loc[:,interested_individuals]\n",
        "  #df_enformer = np.transpose(pd.DataFrame(enformer_predictions)).loc[:, df_geuvadis.columns]\n",
        "  df_enformer = pd.DataFrame(enformer_predictions[interested_gene], index=[0]).loc[:, df_geuvadis.columns]\n",
        "\n",
        "  # concatenate both\n",
        "  df_all = pd.concat([df_enformer, df_geuvadis], axis=0)\n",
        "  df_all.index = ['Enformer', 'GEUVADIS']\n",
        "\n",
        "  # plotting\n",
        "  sns.regplot(x=df_all.iloc[0,:], y=df_all.iloc[1,:], color='blue').set(title='Enformer vs. Geuvadis predictions on {} individuals for gene {}'.format(len(df_all.columns), interested_gene))\n",
        "  \n",
        "  # correlation coefficient\n",
        "  corr_coef_geu = np.corrcoef(x=df_all.iloc[0,:], y=df_all.iloc[1,:])[0][1]\n",
        "\n",
        "  return([df_all, corr_coef_geu])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t4pKHznmPx_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyQ6QOVP77r8"
      },
      "source": [
        "# Run Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make predictions we use one of the functions defined in the **'Code'** section, namely : *run_predictions*. It requires three parameters: gene_intervals, tss_dataframe, and an individuals_list. Let's prepare them, and we can check whether they are all avaliable in our drive along the way."
      ],
      "metadata": {
        "id": "sdUEHO4ue51Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-DaPq4G8Dx4"
      },
      "source": [
        "## Prepare Gene Interval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czNE-eQAGM-9"
      },
      "source": [
        "1. set index as the gene name\n",
        "2. transpose the dataframe so the column name is now the gene name, and the column values are chr, start, and end.\n",
        "3. because the function: to_dict, 'list' - keys are column names, values are lists of column data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = local_path + 'data/target_gene_info.csv'\n",
        "df_full_target_genes = pd.read_csv(path, index_col = 'Unnamed: 0')"
      ],
      "metadata": {
        "id": "rt3qxZI-xsip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-ouqSMbId9z"
      },
      "outputs": [],
      "source": [
        "df_full_target_genes['chr'] = df_full_target_genes['chr'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "JO8_PnfQ-n9Z",
        "outputId": "6199df3e-e844-4dba-9675-7ee5a4a518c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gene_name SERPINB1    KBTBD2      GCDH    ZNF493      MANBA    ZNF586  \\\n",
              "chr              6         7        19        19          4        19   \n",
              "start      2832566  32907784  13001974  21579931  103552660  58280997   \n",
              "end        2842240  32933743  13010783  21610375  103682151  58320617   \n",
              "\n",
              "gene_name      THOC3    ZNF567     PCYT1A    PAPD7  ...      HELB   SLC16A9  \\\n",
              "chr                5        19          3        5  ...        12        10   \n",
              "start      175344876  37178530  195941093  6714718  ...  66696325  61410523   \n",
              "end        175461683  37214248  196014828  6757161  ...  66737423  61495760   \n",
              "\n",
              "gene_name      FCRL3     MCM8    MRPL21      FAAH    SLC36A1       PFN2  \\\n",
              "chr                1       20        11         1          5          3   \n",
              "start      157646271  5931298  68658744  46859937  150816607  149682691   \n",
              "end        157670775  5975852  68671303  46879520  150871942  149768575   \n",
              "\n",
              "gene_name      COG3     ICAM5  \n",
              "chr              13        19  \n",
              "start      46039060  10400655  \n",
              "end        46110765  10407453  \n",
              "\n",
              "[3 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72dfcc6e-c6d3-485c-be66-ccb34e77e231\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>gene_name</th>\n",
              "      <th>SERPINB1</th>\n",
              "      <th>KBTBD2</th>\n",
              "      <th>GCDH</th>\n",
              "      <th>ZNF493</th>\n",
              "      <th>MANBA</th>\n",
              "      <th>ZNF586</th>\n",
              "      <th>THOC3</th>\n",
              "      <th>ZNF567</th>\n",
              "      <th>PCYT1A</th>\n",
              "      <th>PAPD7</th>\n",
              "      <th>...</th>\n",
              "      <th>HELB</th>\n",
              "      <th>SLC16A9</th>\n",
              "      <th>FCRL3</th>\n",
              "      <th>MCM8</th>\n",
              "      <th>MRPL21</th>\n",
              "      <th>FAAH</th>\n",
              "      <th>SLC36A1</th>\n",
              "      <th>PFN2</th>\n",
              "      <th>COG3</th>\n",
              "      <th>ICAM5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>chr</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>start</th>\n",
              "      <td>2832566</td>\n",
              "      <td>32907784</td>\n",
              "      <td>13001974</td>\n",
              "      <td>21579931</td>\n",
              "      <td>103552660</td>\n",
              "      <td>58280997</td>\n",
              "      <td>175344876</td>\n",
              "      <td>37178530</td>\n",
              "      <td>195941093</td>\n",
              "      <td>6714718</td>\n",
              "      <td>...</td>\n",
              "      <td>66696325</td>\n",
              "      <td>61410523</td>\n",
              "      <td>157646271</td>\n",
              "      <td>5931298</td>\n",
              "      <td>68658744</td>\n",
              "      <td>46859937</td>\n",
              "      <td>150816607</td>\n",
              "      <td>149682691</td>\n",
              "      <td>46039060</td>\n",
              "      <td>10400655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>end</th>\n",
              "      <td>2842240</td>\n",
              "      <td>32933743</td>\n",
              "      <td>13010783</td>\n",
              "      <td>21610375</td>\n",
              "      <td>103682151</td>\n",
              "      <td>58320617</td>\n",
              "      <td>175461683</td>\n",
              "      <td>37214248</td>\n",
              "      <td>196014828</td>\n",
              "      <td>6757161</td>\n",
              "      <td>...</td>\n",
              "      <td>66737423</td>\n",
              "      <td>61495760</td>\n",
              "      <td>157670775</td>\n",
              "      <td>5975852</td>\n",
              "      <td>68671303</td>\n",
              "      <td>46879520</td>\n",
              "      <td>150871942</td>\n",
              "      <td>149768575</td>\n",
              "      <td>46110765</td>\n",
              "      <td>10407453</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 100 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72dfcc6e-c6d3-485c-be66-ccb34e77e231')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72dfcc6e-c6d3-485c-be66-ccb34e77e231 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72dfcc6e-c6d3-485c-be66-ccb34e77e231');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df_full_target_genes.set_index('gene_name').T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoTRvBYtBqz-"
      },
      "outputs": [],
      "source": [
        "my_intervals = df_full_target_genes.set_index('gene_name').T.to_dict('list')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsW1wyC_HYz0"
      },
      "source": [
        "Now we have a list (*my_intervals*) containing 100 genes of our interest for one of the parameters of the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIEPUo6Iq_bN"
      },
      "outputs": [],
      "source": [
        "list_of_genes = df_full_target_genes['gene_name'].to_list()  # prepare a list of genes for plotting"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TSS Dataframe Preparation"
      ],
      "metadata": {
        "id": "lIs5CXLxJG1k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNnruFdMEN4e"
      },
      "source": [
        "Read into a list, the list contains dataframes that are the TSS per gene for the chromosomes we are interested in "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a list containing all the chromosome numbers that we have resource for\n",
        "chromosomes = ['6','7','19','4','5','3','18','21','1','15','22','11','2','17','12','9','16','14','10','13','20']"
      ],
      "metadata": {
        "id": "7PF-On_FJ5dY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OP4lz09v_zCx"
      },
      "outputs": [],
      "source": [
        "tss = []\n",
        "for chr in chromosomes:\n",
        "  df = pd.read_table('/content/drive/MyDrive/Capstone_Project_2022/data/tss_by_chr/chr' +chr+ '_tss_by_gene.txt', sep='\\t')\n",
        "  tss.append(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## List of Individuals Preparation"
      ],
      "metadata": {
        "id": "WSbCj4CHJ9oP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nokzAGzvud-f"
      },
      "outputs": [],
      "source": [
        "path1 = \"/content/drive/MyDrive/Capstone_Project_2022/data/CEU_sample_group.csv\"\n",
        "CEU_sample_group = pd.read_csv(path1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud1TebGxve6i"
      },
      "outputs": [],
      "source": [
        "path2 = \"/content/drive/MyDrive/Capstone_Project_2022/data/YRI_sample_group.csv\"\n",
        "YRI_sample_group = pd.read_csv(path2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Predictions"
      ],
      "metadata": {
        "id": "DvJLIao1KGXn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvSTbAiXNfta"
      },
      "source": [
        "We have everything ready now, we can start generating haplotype sum predictions for YRI and CEU sample groups. This would take a while."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkFtKNsHfIXM"
      },
      "source": [
        "We still need the model itself. The model has been graciously hosted on [Tensorflow Hub](https://tfhub.dev/deepmind/enformer/1), which hosts many other models too. You can click on the link and explore. When you click the link, you can see that the model is about 892 Mb large. Quite big. \n",
        "We will use the url to the model to download and use it here. \n",
        "\n",
        "Earlier, we defined an Enformer class (see the codes section). We will load the model into this class. The model has been trained and the weights are freely available. All we need to do is to load this model and use it. Neat. \n",
        "\n",
        "We also defined a class FastaStringExtractor, that can help us extract raw sequences from fasta files given the intervals we want. We will make use of this class too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC-pgC35DgnL"
      },
      "outputs": [],
      "source": [
        "model = Enformer(model_path) # here we load the model architecture. \n",
        "\n",
        "fasta_extractor = FastaStringExtractor(fasta_file) # we define a class called fasta_extractor to help us extra raw sequence data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ966Kj-xNs-"
      },
      "source": [
        "for YRI group\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCMmurxWqs4M"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "test = YRI_sample_group[\"individual\"].values.tolist()\n",
        "filepath = '/content/drive/MyDrive/Capstone_Project_2022/results/YRI_Haplotype_Sum.csv'\n",
        "\n",
        "# Making sure the file exists before writing into it. \n",
        "if not os.path.exists(filepath):\n",
        "  df_YRI_Hap_Sum = pd.DataFrame(index = test, columns = list_of_genes)\n",
        "  df_YRI_Hap_Sum.to_csv(filepath)\n",
        "  \n",
        "list_of_genes = df_full_target_genes['gene_name'].to_list()  # prepare a list of genes for plotting\n",
        "\n",
        "start = timeit.default_timer()\n",
        "\n",
        "# i is index of the individual list\n",
        "for i in range(len(test)): \n",
        "  df_YRI_Hap_Sum = pd.read_csv(filepath, index_col = 'Unnamed: 0', na_values='NaN', keep_default_na=False)\n",
        "  if df_YRI_Hap_Sum.at[test[i],list_of_genes[0]]: \n",
        "    #print('value exists')\n",
        "    continue\n",
        "  else:\n",
        "    test_predictions = run_predictions(gene_intervals=my_intervals, tss_dataframe=tss, individuals_list=test[i:i+1]) # here we make predictions and save it.\n",
        "    for gene in range(len(list_of_genes)):\n",
        "      df_YRI_Hap_Sum.at[test[i],list_of_genes[gene]]=pd.DataFrame(test_predictions[0][list_of_genes[gene]][test[i]]).sum().sum()\n",
        "    df_YRI_Hap_Sum.to_csv(filepath)\n",
        "    \n",
        "stop = timeit.default_timer()\n",
        "print('Time: ', stop - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8W1_FrKNpx5"
      },
      "source": [
        "for CEU group\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUUHx-xpNvSQ"
      },
      "outputs": [],
      "source": [
        "test = CEU_sample_group[\"individual\"].values.tolist()\n",
        "filepath = '/content/drive/MyDrive/Capstone_Project_2022/results/CEU_Haplotype_Sum.csv'\n",
        "\n",
        "# Check whether there is a file named CEU_Haplotype_Sum.csv, if not create one\n",
        "if not os.path.exists(filepath):\n",
        "  df_CEU_Haplotype_Sum = pd.DataFrame(index = test, columns = list_of_genes)\n",
        "  df_CEU_Haplotype_Sum.to_csv(filepath)\n",
        "\n",
        "list_of_genes = df_full_target_genes['gene_name'].to_list()  # prepare a list of genes for plotting\n",
        "\n",
        "start = timeit.default_timer()\n",
        "\n",
        "# i is index of the individual list\n",
        "for i in range(len(test)): \n",
        "  df_hapScoreSum = pd.read_csv(filepath, index_col = 'Unnamed: 0', na_values='NaN', keep_default_na=False)\n",
        "  if df_hapScoreSum.at[test[i],list_of_genes[0]]: \n",
        "    #print('value exists')\n",
        "    continue\n",
        "  else:\n",
        "    test_predictions = run_predictions(gene_intervals=my_intervals, tss_dataframe=tss, individuals_list=test[i:i+1]) # here we make predictions and save it.\n",
        "    for gene in range(len(list_of_genes)):\n",
        "      df_hapScoreSum.at[test[i],list_of_genes[gene]]=pd.DataFrame(test_predictions[0][list_of_genes[gene]][test[i]]).sum().sum()\n",
        "    df_hapScoreSum.to_csv(filepath)\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('Time: ', stop - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**By now there should be two csv files in your drive. We can move on to the next script where we will plot some graphs for visulization and do some analysis.**  "
      ],
      "metadata": {
        "id": "tkom4WeRPxFT"
      }
    }
  ]
}